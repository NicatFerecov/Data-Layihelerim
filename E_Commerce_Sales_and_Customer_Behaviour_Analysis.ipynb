{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfGBZXAuTAxMbMxpH1CnbT"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# E-Commerce Sales and Customer Behavior Analysis - Complete Implementation\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Machine Learning libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Statistical libraries\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Visualization libraries\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "print(\"📊 E-Commerce Sales and Customer Behavior Analysis\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# =============================================================================\n",
        "# PART 1: DATA GENERATION\n",
        "# =============================================================================\n",
        "\n",
        "class ECommerceDataGenerator:\n",
        "    \"\"\"Generate realistic e-commerce dataset\"\"\"\n",
        "\n",
        "    def __init__(self, n_customers=5000, n_products=500, n_orders=25000):\n",
        "        self.n_customers = n_customers\n",
        "        self.n_products = n_products\n",
        "        self.n_orders = n_orders\n",
        "\n",
        "    def generate_customers(self):\n",
        "        \"\"\"Generate customer data\"\"\"\n",
        "        countries = ['USA', 'UK', 'Germany', 'France', 'Canada', 'Australia', 'Japan', 'Brazil']\n",
        "        segments = ['Premium', 'Standard', 'Budget']\n",
        "\n",
        "        customers = []\n",
        "        for i in range(self.n_customers):\n",
        "            reg_date = datetime(2023, 1, 1) + timedelta(days=random.randint(0, 730))\n",
        "            birth_date = datetime(1960, 1, 1) + timedelta(days=random.randint(0, 20000))\n",
        "\n",
        "            customer = {\n",
        "                'customer_id': f'C{i+1:05d}',\n",
        "                'first_name': f'Customer{i+1}',\n",
        "                'last_name': f'Last{i+1}',\n",
        "                'email': f'customer{i+1}@email.com',\n",
        "                'registration_date': reg_date,\n",
        "                'birth_date': birth_date,\n",
        "                'gender': random.choice(['M', 'F']),\n",
        "                'country': random.choice(countries),\n",
        "                'customer_segment': random.choice(segments),\n",
        "                'lifetime_value': round(random.uniform(100, 5000), 2)\n",
        "            }\n",
        "            customers.append(customer)\n",
        "\n",
        "        return pd.DataFrame(customers)\n",
        "\n",
        "    def generate_products(self):\n",
        "        \"\"\"Generate product data\"\"\"\n",
        "        categories = ['Electronics', 'Clothing', 'Home', 'Books', 'Sports', 'Beauty']\n",
        "        brands = ['BrandA', 'BrandB', 'BrandC', 'BrandD', 'BrandE']\n",
        "\n",
        "        products = []\n",
        "        for i in range(self.n_products):\n",
        "            category = random.choice(categories)\n",
        "            cost_price = round(random.uniform(10, 500), 2)\n",
        "\n",
        "            product = {\n",
        "                'product_id': f'P{i+1:05d}',\n",
        "                'product_name': f'{category} Product {i+1}',\n",
        "                'category': category,\n",
        "                'brand': random.choice(brands),\n",
        "                'cost_price': cost_price,\n",
        "                'unit_price': round(cost_price * random.uniform(1.5, 3.0), 2),\n",
        "                'weight': round(random.uniform(0.1, 5.0), 2),\n",
        "                'launch_date': datetime(2023, 1, 1) + timedelta(days=random.randint(0, 365))\n",
        "            }\n",
        "            products.append(product)\n",
        "\n",
        "        return pd.DataFrame(products)\n",
        "\n",
        "    def generate_orders(self, customers_df, products_df):\n",
        "        \"\"\"Generate order data\"\"\"\n",
        "        orders = []\n",
        "        order_id = 1\n",
        "\n",
        "        for _, customer in customers_df.iterrows():\n",
        "            # Number of orders per customer based on segment\n",
        "            if customer['customer_segment'] == 'Premium':\n",
        "                n_orders = random.randint(10, 30)\n",
        "            elif customer['customer_segment'] == 'Standard':\n",
        "                n_orders = random.randint(3, 15)\n",
        "            else:  # Budget\n",
        "                n_orders = random.randint(1, 8)\n",
        "\n",
        "            for _ in range(n_orders):\n",
        "                if order_id > self.n_orders:\n",
        "                    break\n",
        "\n",
        "                order_date = customer['registration_date'] + timedelta(days=random.randint(0, 365))\n",
        "                product = products_df.sample(1).iloc[0]\n",
        "                quantity = random.randint(1, 5)\n",
        "\n",
        "                order = {\n",
        "                    'order_id': f'O{order_id:06d}',\n",
        "                    'customer_id': customer['customer_id'],\n",
        "                    'product_id': product['product_id'],\n",
        "                    'order_date': order_date,\n",
        "                    'quantity': quantity,\n",
        "                    'unit_price': product['unit_price'],\n",
        "                    'total_amount': round(quantity * product['unit_price'], 2),\n",
        "                    'shipping_cost': round(random.uniform(5, 25), 2),\n",
        "                    'discount_applied': round(random.uniform(0, 20), 2),\n",
        "                    'payment_method': random.choice(['Credit Card', 'PayPal', 'Bank Transfer']),\n",
        "                    'order_status': random.choice(['Completed', 'Pending', 'Cancelled'])\n",
        "                }\n",
        "                orders.append(order)\n",
        "                order_id += 1\n",
        "\n",
        "        return pd.DataFrame(orders)\n",
        "\n",
        "    def generate_customer_behavior(self, customers_df):\n",
        "        \"\"\"Generate customer behavior data\"\"\"\n",
        "        behavior = []\n",
        "\n",
        "        for _, customer in customers_df.iterrows():\n",
        "            last_login = datetime.now() - timedelta(days=random.randint(0, 90))\n",
        "\n",
        "            behavior_data = {\n",
        "                'customer_id': customer['customer_id'],\n",
        "                'last_login': last_login,\n",
        "                'page_views': random.randint(10, 500),\n",
        "                'time_on_site': round(random.uniform(5, 120), 2),\n",
        "                'cart_abandonment_rate': round(random.uniform(0, 0.8), 2),\n",
        "                'email_open_rate': round(random.uniform(0.1, 0.9), 2),\n",
        "                'support_tickets': random.randint(0, 10),\n",
        "                'review_count': random.randint(0, 50),\n",
        "                'average_rating': round(random.uniform(1, 5), 1)\n",
        "            }\n",
        "            behavior.append(behavior_data)\n",
        "\n",
        "        return pd.DataFrame(behavior)\n",
        "\n",
        "# Generate datasets\n",
        "print(\"🔄 Generating datasets...\")\n",
        "generator = ECommerceDataGenerator()\n",
        "\n",
        "customers_df = generator.generate_customers()\n",
        "products_df = generator.generate_products()\n",
        "orders_df = generator.generate_orders(customers_df, products_df)\n",
        "behavior_df = generator.generate_customer_behavior(customers_df)\n",
        "\n",
        "print(f\"✅ Generated {len(customers_df)} customers\")\n",
        "print(f\"✅ Generated {len(products_df)} products\")\n",
        "print(f\"✅ Generated {len(orders_df)} orders\")\n",
        "print(f\"✅ Generated {len(behavior_df)} behavior records\")\n",
        "\n",
        "# =============================================================================\n",
        "# PART 2: DATA EXPLORATION AND CLEANING\n",
        "# =============================================================================\n",
        "\n",
        "class DataExplorer:\n",
        "    \"\"\"Data exploration and cleaning utilities\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def explore_dataset(df, name):\n",
        "        \"\"\"Explore dataset basic information\"\"\"\n",
        "        print(f\"\\n📊 {name} Dataset Overview\")\n",
        "        print(\"-\" * 40)\n",
        "        print(f\"Shape: {df.shape}\")\n",
        "        print(f\"Columns: {list(df.columns)}\")\n",
        "        print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
        "        print(f\"Data types:\\n{df.dtypes}\")\n",
        "        print(f\"\\nFirst 3 rows:\\n{df.head(3)}\")\n",
        "        return df.describe()\n",
        "\n",
        "    @staticmethod\n",
        "    def clean_data(customers_df, products_df, orders_df, behavior_df):\n",
        "        \"\"\"Clean and prepare data\"\"\"\n",
        "        print(\"\\n🔧 Cleaning data...\")\n",
        "\n",
        "        # Convert date columns\n",
        "        customers_df['registration_date'] = pd.to_datetime(customers_df['registration_date'])\n",
        "        customers_df['birth_date'] = pd.to_datetime(customers_df['birth_date'])\n",
        "        orders_df['order_date'] = pd.to_datetime(orders_df['order_date'])\n",
        "        behavior_df['last_login'] = pd.to_datetime(behavior_df['last_login'])\n",
        "\n",
        "        # Calculate age\n",
        "        customers_df['age'] = (datetime.now() - customers_df['birth_date']).dt.days // 365\n",
        "\n",
        "        # Filter completed orders only\n",
        "        orders_df = orders_df[orders_df['order_status'] == 'Completed'].copy()\n",
        "\n",
        "        # Calculate net amount (after discount)\n",
        "        orders_df['net_amount'] = orders_df['total_amount'] - orders_df['discount_applied']\n",
        "\n",
        "        # Add profit calculation\n",
        "        orders_df = orders_df.merge(products_df[['product_id', 'cost_price']], on='product_id')\n",
        "        orders_df['profit'] = (orders_df['unit_price'] - orders_df['cost_price']) * orders_df['quantity']\n",
        "\n",
        "        print(\"✅ Data cleaning completed\")\n",
        "        return customers_df, products_df, orders_df, behavior_df\n",
        "\n",
        "# Explore datasets\n",
        "explorer = DataExplorer()\n",
        "explorer.explore_dataset(customers_df, \"Customers\")\n",
        "explorer.explore_dataset(products_df, \"Products\")\n",
        "explorer.explore_dataset(orders_df, \"Orders\")\n",
        "explorer.explore_dataset(behavior_df, \"Behavior\")\n",
        "\n",
        "# Clean data\n",
        "customers_df, products_df, orders_df, behavior_df = explorer.clean_data(\n",
        "    customers_df, products_df, orders_df, behavior_df\n",
        ")\n",
        "\n",
        "# =============================================================================\n",
        "# PART 3: PROFITABILITY ANALYSIS\n",
        "# =============================================================================\n",
        "\n",
        "class ProfitabilityAnalyzer:\n",
        "    \"\"\"Analyze profitability across different dimensions\"\"\"\n",
        "\n",
        "    def __init__(self, orders_df, products_df, customers_df):\n",
        "        self.orders_df = orders_df\n",
        "        self.products_df = products_df\n",
        "        self.customers_df = customers_df\n",
        "\n",
        "    def product_profitability(self):\n",
        "        \"\"\"Analyze product profitability\"\"\"\n",
        "        print(\"\\n💰 Product Profitability Analysis\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Product performance metrics\n",
        "        product_metrics = self.orders_df.groupby('product_id').agg({\n",
        "            'quantity': 'sum',\n",
        "            'total_amount': 'sum',\n",
        "            'profit': 'sum',\n",
        "            'order_id': 'count'\n",
        "        }).rename(columns={'order_id': 'order_count'})\n",
        "\n",
        "        # Merge with product details\n",
        "        product_metrics = product_metrics.merge(\n",
        "            self.products_df[['product_id', 'product_name', 'category', 'brand']],\n",
        "            on='product_id'\n",
        "        )\n",
        "\n",
        "        # Calculate profitability metrics\n",
        "        product_metrics['profit_margin'] = product_metrics['profit'] / product_metrics['total_amount']\n",
        "        product_metrics['avg_order_value'] = product_metrics['total_amount'] / product_metrics['order_count']\n",
        "\n",
        "        # Top profitable products\n",
        "        top_products = product_metrics.nlargest(10, 'profit')\n",
        "        print(\"Top 10 Most Profitable Products:\")\n",
        "        print(top_products[['product_name', 'category', 'profit', 'profit_margin']].round(2))\n",
        "\n",
        "        return product_metrics\n",
        "\n",
        "    def category_analysis(self):\n",
        "        \"\"\"Analyze category performance\"\"\"\n",
        "        print(\"\\n📊 Category Performance Analysis\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Category metrics\n",
        "        category_metrics = self.orders_df.merge(\n",
        "            self.products_df[['product_id', 'category']], on='product_id'\n",
        "        ).groupby('category').agg({\n",
        "            'total_amount': 'sum',\n",
        "            'profit': 'sum',\n",
        "            'quantity': 'sum',\n",
        "            'order_id': 'count'\n",
        "        }).rename(columns={'order_id': 'order_count'})\n",
        "\n",
        "        category_metrics['profit_margin'] = category_metrics['profit'] / category_metrics['total_amount']\n",
        "        category_metrics = category_metrics.sort_values('profit', ascending=False)\n",
        "\n",
        "        print(\"Category Performance:\")\n",
        "        print(category_metrics.round(2))\n",
        "\n",
        "        return category_metrics\n",
        "\n",
        "    def customer_segmentation(self):\n",
        "        \"\"\"RFM Analysis for customer segmentation\"\"\"\n",
        "        print(\"\\n👥 Customer Segmentation (RFM Analysis)\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Calculate RFM metrics\n",
        "        current_date = self.orders_df['order_date'].max()\n",
        "\n",
        "        rfm = self.orders_df.groupby('customer_id').agg({\n",
        "            'order_date': lambda x: (current_date - x.max()).days,  # Recency\n",
        "            'order_id': 'count',  # Frequency\n",
        "            'total_amount': 'sum'  # Monetary\n",
        "        }).rename(columns={\n",
        "            'order_date': 'recency',\n",
        "            'order_id': 'frequency',\n",
        "            'total_amount': 'monetary'\n",
        "        })\n",
        "\n",
        "        # Calculate RFM scores\n",
        "        rfm['r_score'] = pd.qcut(rfm['recency'].rank(method='first'), 5, labels=[5,4,3,2,1])\n",
        "        rfm['f_score'] = pd.qcut(rfm['frequency'].rank(method='first'), 5, labels=[1,2,3,4,5])\n",
        "        rfm['m_score'] = pd.qcut(rfm['monetary'].rank(method='first'), 5, labels=[1,2,3,4,5])\n",
        "\n",
        "        # Combine RFM scores\n",
        "        rfm['rfm_score'] = rfm['r_score'].astype(str) + rfm['f_score'].astype(str) + rfm['m_score'].astype(str)\n",
        "\n",
        "        # Segment customers\n",
        "        def segment_customers(row):\n",
        "            if row['rfm_score'] in ['555', '554', '544', '545', '454', '455', '445']:\n",
        "                return 'Champions'\n",
        "            elif row['rfm_score'] in ['543', '444', '435', '355', '354', '345', '344', '335']:\n",
        "                return 'Loyal Customers'\n",
        "            elif row['rfm_score'] in ['512', '511', '422', '421', '412', '411', '311']:\n",
        "                return 'Potential Loyalists'\n",
        "            elif row['rfm_score'] in ['533', '532', '531', '523', '522', '521', '515', '514']:\n",
        "                return 'New Customers'\n",
        "            elif row['rfm_score'] in ['155', '154', '144', '214', '215', '115', '114']:\n",
        "                return 'At Risk'\n",
        "            else:\n",
        "                return 'Others'\n",
        "\n",
        "        rfm['segment'] = rfm.apply(segment_customers, axis=1)\n",
        "\n",
        "        # Segment analysis\n",
        "        segment_analysis = rfm.groupby('segment').agg({\n",
        "            'recency': 'mean',\n",
        "            'frequency': 'mean',\n",
        "            'monetary': 'mean'\n",
        "        }).round(2)\n",
        "\n",
        "        print(\"Customer Segments:\")\n",
        "        print(segment_analysis)\n",
        "\n",
        "        return rfm\n",
        "\n",
        "# Perform profitability analysis\n",
        "profitability = ProfitabilityAnalyzer(orders_df, products_df, customers_df)\n",
        "product_metrics = profitability.product_profitability()\n",
        "category_metrics = profitability.category_analysis()\n",
        "rfm_analysis = profitability.customer_segmentation()\n",
        "\n",
        "# =============================================================================\n",
        "# PART 4: CHURN PREDICTION MODEL\n",
        "# =============================================================================\n",
        "\n",
        "class ChurnPredictor:\n",
        "    \"\"\"Build customer churn prediction model\"\"\"\n",
        "\n",
        "    def __init__(self, orders_df, customers_df, behavior_df):\n",
        "        self.orders_df = orders_df\n",
        "        self.customers_df = customers_df\n",
        "        self.behavior_df = behavior_df\n",
        "\n",
        "    def prepare_features(self):\n",
        "        \"\"\"Prepare features for churn prediction\"\"\"\n",
        "        print(\"\\n🔮 Preparing Churn Prediction Features\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Customer purchase behavior\n",
        "        current_date = self.orders_df['order_date'].max()\n",
        "        customer_features = self.orders_df.groupby('customer_id').agg({\n",
        "            'order_date': [\n",
        "                lambda x: (current_date - x.max()).days,  # Days since last order\n",
        "                lambda x: (current_date - x.min()).days,  # Customer tenure\n",
        "                'count'  # Total orders\n",
        "            ],\n",
        "            'total_amount': ['sum', 'mean', 'std'],\n",
        "            'quantity': ['sum', 'mean'],\n",
        "            'profit': ['sum', 'mean']\n",
        "        }).round(2)\n",
        "\n",
        "        # Flatten column names\n",
        "        customer_features.columns = [\n",
        "            'days_since_last_order', 'customer_tenure', 'total_orders',\n",
        "            'total_spent', 'avg_order_value', 'std_order_value',\n",
        "            'total_quantity', 'avg_quantity', 'total_profit', 'avg_profit'\n",
        "        ]\n",
        "\n",
        "        # Fill NaN values\n",
        "        customer_features['std_order_value'] = customer_features['std_order_value'].fillna(0)\n",
        "\n",
        "        # Merge with customer demographics\n",
        "        customer_features = customer_features.merge(\n",
        "            self.customers_df[['customer_id', 'customer_segment', 'age', 'country']],\n",
        "            on='customer_id', how='left'\n",
        "        )\n",
        "\n",
        "        # Merge with behavior data\n",
        "        customer_features = customer_features.merge(\n",
        "            self.behavior_df[['customer_id', 'page_views', 'time_on_site',\n",
        "                            'cart_abandonment_rate', 'email_open_rate',\n",
        "                            'support_tickets', 'review_count']],\n",
        "            on='customer_id', how='left'\n",
        "        )\n",
        "\n",
        "        # Define churn (no order in last 60 days)\n",
        "        customer_features['is_churned'] = (customer_features['days_since_last_order'] > 60).astype(int)\n",
        "\n",
        "        print(f\"Churn rate: {customer_features['is_churned'].mean():.2%}\")\n",
        "\n",
        "        return customer_features\n",
        "\n",
        "    def build_model(self, features_df):\n",
        "        \"\"\"Build and train churn prediction model\"\"\"\n",
        "        print(\"\\n🤖 Building Churn Prediction Model\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Prepare features\n",
        "        feature_columns = [\n",
        "            'customer_tenure', 'total_orders', 'total_spent', 'avg_order_value',\n",
        "            'total_quantity', 'avg_quantity', 'age', 'page_views', 'time_on_site',\n",
        "            'cart_abandonment_rate', 'email_open_rate', 'support_tickets', 'review_count'\n",
        "        ]\n",
        "\n",
        "        # Handle missing values\n",
        "        features_df[feature_columns] = features_df[feature_columns].fillna(0)\n",
        "\n",
        "        # Encode categorical variables\n",
        "        le_segment = LabelEncoder()\n",
        "        le_country = LabelEncoder()\n",
        "\n",
        "        features_df['segment_encoded'] = le_segment.fit_transform(features_df['customer_segment'])\n",
        "        features_df['country_encoded'] = le_country.fit_transform(features_df['country'])\n",
        "\n",
        "        feature_columns.extend(['segment_encoded', 'country_encoded'])\n",
        "\n",
        "        # Prepare training data\n",
        "        X = features_df[feature_columns]\n",
        "        y = features_df['is_churned']\n",
        "\n",
        "        # Split data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Scale features\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        # Train models\n",
        "        models = {\n",
        "            'Logistic Regression': LogisticRegression(random_state=42),\n",
        "            'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "        }\n",
        "\n",
        "        results = {}\n",
        "        for name, model in models.items():\n",
        "            # Train model\n",
        "            if name == 'Logistic Regression':\n",
        "                model.fit(X_train_scaled, y_train)\n",
        "                y_pred = model.predict(X_test_scaled)\n",
        "                y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "            else:\n",
        "                model.fit(X_train, y_train)\n",
        "                y_pred = model.predict(X_test)\n",
        "                y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "            # Evaluate model\n",
        "            auc_score = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "            results[name] = {\n",
        "                'model': model,\n",
        "                'auc_score': auc_score,\n",
        "                'predictions': y_pred,\n",
        "                'probabilities': y_pred_proba\n",
        "            }\n",
        "\n",
        "            print(f\"\\n{name} Results:\")\n",
        "            print(f\"AUC Score: {auc_score:.3f}\")\n",
        "            print(f\"Classification Report:\\n{classification_report(y_test, y_pred)}\")\n",
        "\n",
        "        return results, X_test, y_test, feature_columns, scaler\n",
        "\n",
        "# Build churn prediction model\n",
        "churn_predictor = ChurnPredictor(orders_df, customers_df, behavior_df)\n",
        "churn_features = churn_predictor.prepare_features()\n",
        "churn_models, X_test, y_test, feature_columns, scaler = churn_predictor.build_model(churn_features)\n",
        "\n",
        "# =============================================================================\n",
        "# PART 5: DYNAMIC PRICING ANALYSIS\n",
        "# =============================================================================\n",
        "\n",
        "class PricingAnalyzer:\n",
        "    \"\"\"Analyze pricing strategies and elasticity\"\"\"\n",
        "\n",
        "    def __init__(self, orders_df, products_df):\n",
        "        self.orders_df = orders_df\n",
        "        self.products_df = products_df\n",
        "\n",
        "    def price_elasticity_analysis(self):\n",
        "        \"\"\"Calculate price elasticity for products\"\"\"\n",
        "        print(\"\\n💲 Price Elasticity Analysis\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Merge orders with products\n",
        "        price_data = self.orders_df.merge(\n",
        "            self.products_df[['product_id', 'category']], on='product_id'\n",
        "        )\n",
        "\n",
        "        # Calculate elasticity by category\n",
        "        elasticity_results = {}\n",
        "\n",
        "        for category in price_data['category'].unique():\n",
        "            cat_data = price_data[price_data['category'] == category].copy()\n",
        "\n",
        "            # Group by price ranges\n",
        "            cat_data['price_range'] = pd.cut(cat_data['unit_price'], bins=5)\n",
        "            price_demand = cat_data.groupby('price_range').agg({\n",
        "                'quantity': 'sum',\n",
        "                'unit_price': 'mean'\n",
        "            }).dropna()\n",
        "\n",
        "            if len(price_demand) > 1:\n",
        "                # Calculate elasticity (% change in quantity / % change in price)\n",
        "                price_changes = price_demand['unit_price'].pct_change().dropna()\n",
        "                quantity_changes = price_demand['quantity'].pct_change().dropna()\n",
        "\n",
        "                if len(price_changes) > 0 and len(quantity_changes) > 0:\n",
        "                    elasticity = (quantity_changes / price_changes).mean()\n",
        "                    elasticity_results[category] = elasticity\n",
        "\n",
        "        print(\"Price Elasticity by Category:\")\n",
        "        for category, elasticity in elasticity_results.items():\n",
        "            print(f\"{category}: {elasticity:.2f}\")\n",
        "\n",
        "        return elasticity_results\n",
        "\n",
        "    def optimal_pricing_recommendation(self):\n",
        "        \"\"\"Recommend optimal pricing strategies\"\"\"\n",
        "        print(\"\\n🎯 Optimal Pricing Recommendations\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Product performance analysis\n",
        "        product_analysis = self.orders_df.groupby('product_id').agg({\n",
        "            'unit_price': 'mean',\n",
        "            'quantity': 'sum',\n",
        "            'profit': 'sum',\n",
        "            'total_amount': 'sum'\n",
        "        })\n",
        "\n",
        "        # Merge with product info\n",
        "        product_analysis = product_analysis.merge(\n",
        "            self.products_df[['product_id', 'category', 'cost_price']], on='product_id'\n",
        "        )\n",
        "\n",
        "        # Calculate metrics\n",
        "        product_analysis['profit_margin'] = product_analysis['profit'] / product_analysis['total_amount']\n",
        "        product_analysis['markup'] = (product_analysis['unit_price'] - product_analysis['cost_price']) / product_analysis['cost_price']\n",
        "\n",
        "        # Pricing recommendations\n",
        "        def pricing_recommendation(row):\n",
        "            if row['profit_margin'] < 0.2:\n",
        "                return 'Increase Price'\n",
        "            elif row['profit_margin'] > 0.6:\n",
        "                return 'Consider Decreasing Price'\n",
        "            else:\n",
        "                return 'Optimal Range'\n",
        "\n",
        "        product_analysis['recommendation'] = product_analysis.apply(pricing_recommendation, axis=1)\n",
        "\n",
        "        # Summary by category\n",
        "        category_pricing = product_analysis.groupby('category').agg({\n",
        "            'profit_margin': 'mean',\n",
        "            'markup': 'mean',\n",
        "            'quantity': 'sum'\n",
        "        }).round(2)\n",
        "\n",
        "        print(\"Pricing Analysis by Category:\")\n",
        "        print(category_pricing)\n",
        "\n",
        "        return product_analysis\n",
        "\n",
        "# Perform pricing analysis\n",
        "pricing_analyzer = PricingAnalyzer(orders_df, products_df)\n",
        "price_elasticity = pricing_analyzer.price_elasticity_analysis()\n",
        "pricing_recommendations = pricing_analyzer.optimal_pricing_recommendation()\n",
        "\n",
        "# =============================================================================\n",
        "# PART 6: REGIONAL ANALYSIS\n",
        "# =============================================================================\n",
        "\n",
        "class RegionalAnalyzer:\n",
        "    \"\"\"Analyze regional performance and opportunities\"\"\"\n",
        "\n",
        "    def __init__(self, orders_df, customers_df, products_df):\n",
        "        self.orders_df = orders_df\n",
        "        self.customers_df = customers_df\n",
        "        self.products_df = products_df\n",
        "\n",
        "    def regional_performance(self):\n",
        "        \"\"\"Analyze performance by region\"\"\"\n",
        "        print(\"\\n🌍 Regional Performance Analysis\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Regional sales data\n",
        "        regional_data = self.orders_df.merge(\n",
        "            self.customers_df[['customer_id', 'country']], on='customer_id'\n",
        "        ).merge(\n",
        "            self.products_df[['product_id', 'category']], on='product_id'\n",
        "        )\n",
        "\n",
        "        # Regional metrics\n",
        "        regional_metrics = regional_data.groupby('country').agg({\n",
        "            'total_amount': 'sum',\n",
        "            'profit': 'sum',\n",
        "            'quantity': 'sum',\n",
        "            'customer_id': 'nunique',\n",
        "            'order_id': 'count'\n",
        "        }).rename(columns={'customer_id': 'unique_customers', 'order_id': 'total_orders'})\n",
        "\n",
        "        # Calculate additional metrics\n",
        "        regional_metrics['avg_order_value'] = regional_metrics['total_amount'] / regional_metrics['total_orders']\n",
        "        regional_metrics['revenue_per_customer'] = regional_metrics['total_amount'] / regional_metrics['unique_customers']\n",
        "        regional_metrics['profit_margin'] = regional_metrics['profit'] / regional_metrics['total_amount']\n",
        "\n",
        "        regional_metrics = regional_metrics.sort_values('total_amount', ascending=False)\n",
        "\n",
        "        print(\"Regional Performance Metrics:\")\n",
        "        print(regional_metrics.round(2))\n",
        "\n",
        "        return regional_metrics\n",
        "\n",
        "    def category_preferences_by_region(self):\n",
        "        \"\"\"Analyze category preferences by region\"\"\"\n",
        "        print(\"\\n📊 Category Preferences by Region\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Category preferences\n",
        "        regional_categories = self.orders_df.merge(\n",
        "            self.customers_df[['customer_id', 'country']], on='customer_id'\n",
        "        ).merge(\n",
        "            self.products_df[['product_id', 'category']], on='product_id'\n",
        "        )\n",
        "\n",
        "        # Calculate category share by region\n",
        "        category_share = regional_categories.groupby(['country', 'category'])['total_amount'].sum().unstack(fill_value=0)\n",
        "        category_share_pct = category_share.div(category_share.sum(axis=1), axis=0) * 100\n",
        "\n",
        "        print(\"Category Share by Region (%):\")\n",
        "        print(category_share_pct.round(1))\n",
        "\n",
        "        return category_share_pct\n",
        "\n",
        "# Perform regional analysis\n",
        "regional_analyzer = RegionalAnalyzer(orders_df, customers_df, products_df)\n",
        "regional_performance = regional_analyzer.regional_performance()\n",
        "category_preferences = regional_analyzer.category_preferences_by_region()\n",
        "\n",
        "# =============================================================================\n",
        "# PART 7: ADVANCED VISUALIZATIONS\n",
        "# =============================================================================\n",
        "\n",
        "class AdvancedVisualizer:\n",
        "    \"\"\"Create advanced visualizations for insights\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def create_dashboard_plots():\n",
        "        \"\"\"Create comprehensive dashboard plots\"\"\"\n",
        "        print(\"\\n📊 Creating Advanced Visualizations\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Set style\n",
        "        plt.style.use('seaborn-v0_8')\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "        fig.suptitle('E-Commerce Analytics Dashboard', fontsize=16, fontweight='bold')\n",
        "\n",
        "        # 1. Sales Trend Over Time\n",
        "        monthly_sales = orders_df.groupby(orders_df['order_date'].dt.to_period('M'))['total_amount'].sum()\n",
        "        axes[0, 0].plot(monthly_sales.index.astype(str), monthly_sales.values, marker='o')\n",
        "        axes[0, 0].set_title('Monthly Sales Trend')\n",
        "        axes[0, 0].set_xlabel('Month')\n",
        "        axes[0, 0].set_ylabel('Sales Amount')\n",
        "        axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "        # 2. Category Performance\n",
        "        category_data = orders_df.merge(products_df[['product_id', 'category']], on='product_id')\n",
        "        category_sales = category_data.groupby('category')['total_amount'].sum().sort_values(ascending=True)\n",
        "        axes[0, 1].barh(category_sales.index, category_sales.values)\n",
        "        axes[0, 1].set_title('Sales by Category')\n",
        "        axes[0, 1].set_xlabel('Sales Amount')\n",
        "\n",
        "        # 3. Customer Segment Distribution\n",
        "        segment_counts = rfm_analysis['segment'].value_counts()\n",
        "        axes[0, 2].pie(segment_counts.values, labels=segment_counts.index, autopct='%1.1f%%')\n",
        "        axes[0, 2].set_title('Customer Segment Distribution')\n",
        "\n",
        "        # 4. Regional Performance\n",
        "        regional_sales = orders_df.merge(customers_df[['customer_id', 'country']], on='customer_id')\n",
        "        regional_totals = regional_sales.groupby('country')['total_amount'].sum().sort_values(ascending=True)\n",
        "        axes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlXWXFL2pndr",
        "outputId": "d45d6e94-e54c-4a86-9d39-ea58d774a1b2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 E-Commerce Sales and Customer Behavior Analysis\n",
            "============================================================\n",
            "🔄 Generating datasets...\n",
            "✅ Generated 5000 customers\n",
            "✅ Generated 500 products\n",
            "✅ Generated 25000 orders\n",
            "✅ Generated 5000 behavior records\n",
            "\n",
            "📊 Customers Dataset Overview\n",
            "----------------------------------------\n",
            "Shape: (5000, 10)\n",
            "Columns: ['customer_id', 'first_name', 'last_name', 'email', 'registration_date', 'birth_date', 'gender', 'country', 'customer_segment', 'lifetime_value']\n",
            "Missing values: 0\n",
            "Data types:\n",
            "customer_id                  object\n",
            "first_name                   object\n",
            "last_name                    object\n",
            "email                        object\n",
            "registration_date    datetime64[ns]\n",
            "birth_date           datetime64[ns]\n",
            "gender                       object\n",
            "country                      object\n",
            "customer_segment             object\n",
            "lifetime_value              float64\n",
            "dtype: object\n",
            "\n",
            "First 3 rows:\n",
            "  customer_id first_name last_name                email registration_date  \\\n",
            "0      C00001  Customer1     Last1  customer1@email.com        2024-10-16   \n",
            "1      C00002  Customer2     Last2  customer2@email.com        2023-04-15   \n",
            "2      C00003  Customer3     Last3  customer3@email.com        2023-08-12   \n",
            "\n",
            "  birth_date gender country customer_segment  lifetime_value  \n",
            "0 1969-12-27      M  Canada          Premium         1193.73  \n",
            "1 2008-12-04      M   Japan          Premium          246.01  \n",
            "2 1980-11-14      M  France           Budget         3284.43  \n",
            "\n",
            "📊 Products Dataset Overview\n",
            "----------------------------------------\n",
            "Shape: (500, 8)\n",
            "Columns: ['product_id', 'product_name', 'category', 'brand', 'cost_price', 'unit_price', 'weight', 'launch_date']\n",
            "Missing values: 0\n",
            "Data types:\n",
            "product_id              object\n",
            "product_name            object\n",
            "category                object\n",
            "brand                   object\n",
            "cost_price             float64\n",
            "unit_price             float64\n",
            "weight                 float64\n",
            "launch_date     datetime64[ns]\n",
            "dtype: object\n",
            "\n",
            "First 3 rows:\n",
            "  product_id    product_name category   brand  cost_price  unit_price  weight  \\\n",
            "0     P00001  Home Product 1     Home  BrandC      203.21      442.44    1.39   \n",
            "1     P00002  Home Product 2     Home  BrandC      195.00      497.27    0.99   \n",
            "2     P00003  Home Product 3     Home  BrandA      147.28      245.08    0.58   \n",
            "\n",
            "  launch_date  \n",
            "0  2023-11-19  \n",
            "1  2023-12-18  \n",
            "2  2023-12-19  \n",
            "\n",
            "📊 Orders Dataset Overview\n",
            "----------------------------------------\n",
            "Shape: (25000, 11)\n",
            "Columns: ['order_id', 'customer_id', 'product_id', 'order_date', 'quantity', 'unit_price', 'total_amount', 'shipping_cost', 'discount_applied', 'payment_method', 'order_status']\n",
            "Missing values: 0\n",
            "Data types:\n",
            "order_id                    object\n",
            "customer_id                 object\n",
            "product_id                  object\n",
            "order_date          datetime64[ns]\n",
            "quantity                     int64\n",
            "unit_price                 float64\n",
            "total_amount               float64\n",
            "shipping_cost              float64\n",
            "discount_applied           float64\n",
            "payment_method              object\n",
            "order_status                object\n",
            "dtype: object\n",
            "\n",
            "First 3 rows:\n",
            "  order_id customer_id product_id order_date  quantity  unit_price  \\\n",
            "0  O000001      C00001     P00362 2025-06-24         5      361.58   \n",
            "1  O000002      C00001     P00307 2024-11-09         4      658.18   \n",
            "2  O000003      C00001     P00116 2025-08-30         5      186.32   \n",
            "\n",
            "   total_amount  shipping_cost  discount_applied payment_method order_status  \n",
            "0       1807.90          21.95             11.15         PayPal    Cancelled  \n",
            "1       2632.72          13.32              6.38         PayPal      Pending  \n",
            "2        931.60          11.63              8.03    Credit Card      Pending  \n",
            "\n",
            "📊 Behavior Dataset Overview\n",
            "----------------------------------------\n",
            "Shape: (5000, 9)\n",
            "Columns: ['customer_id', 'last_login', 'page_views', 'time_on_site', 'cart_abandonment_rate', 'email_open_rate', 'support_tickets', 'review_count', 'average_rating']\n",
            "Missing values: 0\n",
            "Data types:\n",
            "customer_id                      object\n",
            "last_login               datetime64[ns]\n",
            "page_views                        int64\n",
            "time_on_site                    float64\n",
            "cart_abandonment_rate           float64\n",
            "email_open_rate                 float64\n",
            "support_tickets                   int64\n",
            "review_count                      int64\n",
            "average_rating                  float64\n",
            "dtype: object\n",
            "\n",
            "First 3 rows:\n",
            "  customer_id                 last_login  page_views  time_on_site  \\\n",
            "0      C00001 2025-04-25 08:57:23.422541         107         13.99   \n",
            "1      C00002 2025-05-08 08:57:23.422696         201         41.03   \n",
            "2      C00003 2025-05-01 08:57:23.422760         317        100.22   \n",
            "\n",
            "   cart_abandonment_rate  email_open_rate  support_tickets  review_count  \\\n",
            "0                   0.64             0.40                4             4   \n",
            "1                   0.74             0.59                5            36   \n",
            "2                   0.72             0.75                9            50   \n",
            "\n",
            "   average_rating  \n",
            "0             3.0  \n",
            "1             3.8  \n",
            "2             4.4  \n",
            "\n",
            "🔧 Cleaning data...\n",
            "✅ Data cleaning completed\n",
            "\n",
            "💰 Product Profitability Analysis\n",
            "----------------------------------------\n",
            "Top 10 Most Profitable Products:\n",
            "               product_name     category    profit  profit_margin\n",
            "125      Beauty Product 126       Beauty  76103.90           0.65\n",
            "81   Electronics Product 82  Electronics  60433.07           0.65\n",
            "163      Beauty Product 164       Beauty  60309.75           0.65\n",
            "260        Home Product 261         Home  57635.36           0.64\n",
            "21   Electronics Product 22  Electronics  50331.90           0.59\n",
            "360       Books Product 361        Books  48826.90           0.62\n",
            "45        Beauty Product 46       Beauty  48695.60           0.59\n",
            "221    Clothing Product 222     Clothing  48606.40           0.66\n",
            "97        Sports Product 98       Sports  48580.95           0.65\n",
            "470       Books Product 471        Books  48462.30           0.57\n",
            "\n",
            "📊 Category Performance Analysis\n",
            "----------------------------------------\n",
            "Category Performance:\n",
            "             total_amount      profit  quantity  order_count  profit_margin\n",
            "category                                                                   \n",
            "Sports         2613306.81  1500007.69      4562         1537           0.57\n",
            "Electronics    2695841.43  1489024.04      4663         1576           0.55\n",
            "Beauty         2449936.16  1358103.21      3934         1317           0.55\n",
            "Clothing       2321867.04  1267741.66      4047         1341           0.55\n",
            "Books          2272515.11  1251819.98      3895         1284           0.55\n",
            "Home           2229756.84  1219069.34      3996         1342           0.55\n",
            "\n",
            "👥 Customer Segmentation (RFM Analysis)\n",
            "----------------------------------------\n",
            "Customer Segments:\n",
            "                     recency  frequency  monetary\n",
            "segment                                          \n",
            "At Risk               728.09       7.33  12202.24\n",
            "Champions             187.03       7.85  14524.49\n",
            "Loyal Customers       380.79       6.76  12127.80\n",
            "New Customers         138.32       2.65   3691.90\n",
            "Others                565.54       3.29   5684.15\n",
            "Potential Loyalists   305.52       1.26   1524.73\n",
            "\n",
            "🔮 Preparing Churn Prediction Features\n",
            "----------------------------------------\n",
            "Churn rate: 97.21%\n",
            "\n",
            "🤖 Building Churn Prediction Model\n",
            "----------------------------------------\n",
            "\n",
            "Logistic Regression Results:\n",
            "AUC Score: 0.957\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.08      0.15        12\n",
            "           1       0.97      1.00      0.99       396\n",
            "\n",
            "    accuracy                           0.97       408\n",
            "   macro avg       0.99      0.54      0.57       408\n",
            "weighted avg       0.97      0.97      0.96       408\n",
            "\n",
            "\n",
            "Random Forest Results:\n",
            "AUC Score: 0.972\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        12\n",
            "           1       0.97      1.00      0.99       396\n",
            "\n",
            "    accuracy                           0.97       408\n",
            "   macro avg       0.49      0.50      0.49       408\n",
            "weighted avg       0.94      0.97      0.96       408\n",
            "\n",
            "\n",
            "💲 Price Elasticity Analysis\n",
            "----------------------------------------\n",
            "Price Elasticity by Category:\n",
            "Books: -0.27\n",
            "Beauty: -0.61\n",
            "Sports: -0.32\n",
            "Clothing: -0.73\n",
            "Home: -0.67\n",
            "Electronics: -0.66\n",
            "\n",
            "🎯 Optimal Pricing Recommendations\n",
            "----------------------------------------\n",
            "Pricing Analysis by Category:\n",
            "             profit_margin  markup  quantity\n",
            "category                                    \n",
            "Beauty                0.54    1.24      3934\n",
            "Books                 0.53    1.22      3895\n",
            "Clothing              0.53    1.20      4047\n",
            "Electronics           0.54    1.26      4663\n",
            "Home                  0.53    1.20      3996\n",
            "Sports                0.55    1.32      4562\n",
            "\n",
            "🌍 Regional Performance Analysis\n",
            "----------------------------------------\n",
            "Regional Performance Metrics:\n",
            "           total_amount      profit  quantity  unique_customers  total_orders  \\\n",
            "country                                                                         \n",
            "Japan        2144398.54  1186613.81      3750               280          1255   \n",
            "Brazil       1985773.87  1108392.58      3387               264          1106   \n",
            "UK           1898569.78  1059877.49      3227               263          1067   \n",
            "Australia    1834008.23  1018018.70      3080               260          1064   \n",
            "USA          1699084.15   939805.63      2967               252          1009   \n",
            "France       1680223.16   934674.50      2907               242           976   \n",
            "Germany      1674707.95   927030.85      2922               251           976   \n",
            "Canada       1666457.71   911352.36      2857               228           944   \n",
            "\n",
            "           avg_order_value  revenue_per_customer  profit_margin  \n",
            "country                                                          \n",
            "Japan              1708.68               7658.57           0.55  \n",
            "Brazil             1795.46               7521.87           0.56  \n",
            "UK                 1779.35               7218.90           0.56  \n",
            "Australia          1723.69               7053.88           0.56  \n",
            "USA                1683.93               6742.40           0.55  \n",
            "France             1721.54               6943.07           0.56  \n",
            "Germany            1715.89               6672.14           0.55  \n",
            "Canada             1765.32               7309.03           0.55  \n",
            "\n",
            "📊 Category Preferences by Region\n",
            "----------------------------------------\n",
            "Category Share by Region (%):\n",
            "category   Beauty  Books  Clothing  Electronics  Home  Sports\n",
            "country                                                      \n",
            "Australia    14.4   16.1      14.1         18.4  16.8    20.1\n",
            "Brazil       16.6   15.6      14.2         20.3  15.2    18.1\n",
            "Canada       18.9   13.1      17.7         17.6  16.1    16.6\n",
            "France       17.2   14.5      17.7         18.0  14.7    17.9\n",
            "Germany      17.4   17.5      16.3         16.7  15.8    16.3\n",
            "Japan        16.7   14.9      16.8         19.0  14.9    17.8\n",
            "UK           18.3   13.8      15.4         18.2  15.5    18.8\n",
            "USA          15.0   19.4      15.4         19.3  13.4    17.5\n"
          ]
        }
      ]
    }
  ]
}